{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\workstation\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\workstation\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.12)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\workstation\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\workstation\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import sqlalchemy \n",
    "from sqlalchemy import create_engine as ce\n",
    "from sqlalchemy import text\n",
    "import socket\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and Longitude data for state and districts are downloaded from internet and can be found in csv folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets create connection to Mysql datatbase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'root'\n",
    "password = 'gigabyte'\n",
    "host = 'localhost'\n",
    "port = 3306\n",
    "database = 'phonepe_database'\n",
    "connection = ce (\"mysql+pymysql://{0}:{1}@{2}:{3}/{4}\".format(\n",
    "            user, password, host, port, database\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Connect to the MySQL database\\nengine = create_engine('mysql+mysqlconnector://root:gigabyte@localhost:3306/phonepe_database')\\n\\n# Define the SQL command to create a table\\nsql_create_table = text('CREATE TABLE Agg_Transaction_Table (MyIndex INT NOT NULL AUTO_INCREMENT, State INT, Year INT, Quater INT, Payment_Mode VARCHAR(50), Total_Transactions_count BIGINT, Total_Amount BIGINT, PRIMARY KEY (MyIndex))')\\n\\n# Execute the SQL command to create the table\\nwith engine.begin() as conn:\\n    conn.execute(sql_create_table)\\n\\n# Load the data from a CSV file into a pandas dataframe\\ndf = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/aggregated_transaction.csv')\\n\\n# Insert the data from the dataframe into the MySQL database\\ndf.to_sql('Agg_Transaction_Table', con=engine, if_exists='replace', index=False, chunksize=1000)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "\"\"\"# Connect to the MySQL database\n",
    "engine = create_engine('mysql+mysqlconnector://root:gigabyte@localhost:3306/phonepe_database')\n",
    "\n",
    "# Define the SQL command to create a table\n",
    "sql_create_table = text('CREATE TABLE Agg_Transaction_Table (MyIndex INT NOT NULL AUTO_INCREMENT, State INT, Year INT, Quater INT, Payment_Mode VARCHAR(50), Total_Transactions_count BIGINT, Total_Amount BIGINT, PRIMARY KEY (MyIndex))')\n",
    "\n",
    "# Execute the SQL command to create the table\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql_create_table)\n",
    "\n",
    "# Load the data from a CSV file into a pandas dataframe\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/aggregated_transaction.csv')\n",
    "\n",
    "# Insert the data from the dataframe into the MySQL database\n",
    "df.to_sql('Agg_Transaction_Table', con=engine, if_exists='replace', index=False, chunksize=1000)\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating table in Mysql and inserting CSV and repeating the process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sql \u001b[39m=\u001b[39m text(\u001b[39m'\u001b[39m\u001b[39mCREATE TABLE Agg_Transaction_Table (MyIndex INT NOT NULL AUTO_INCREMENT,State INT,Year INT,Quater INT,Payment_Mode VARCHAR(50),Total_Transactions_count BIGINT,Total_Amount BIGINT,PRIMARY KEY (MyIndex))\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mbegin() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m      3\u001b[0m     conn\u001b[39m.\u001b[39mexecute(sql)\n\u001b[0;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mC:/Users/Workstation/Documents/Phonepe/data extracted/aggregated_transaction.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "sql = text('CREATE TABLE Agg_Transaction_Table (MyIndex INT NOT NULL AUTO_INCREMENT,State INT,Year INT,Quater INT,Payment_Mode VARCHAR(50),Total_Transactions_count BIGINT,Total_Amount BIGINT,PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/aggregated_transaction.csv')\n",
    "df.to_sql('agg_transaction_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sql2 \u001b[39m=\u001b[39m text(\u001b[39m'\u001b[39m\u001b[39mCREATE TABLE agg_userbydevice_table (MyIndex INT NOT NULL AUTO_INCREMENT,State INT,Year INT,Quater INT,Brand VARCHAR(50),Brand_count BIGINT,Brand_percentage BIGINT,PRIMARY KEY (MyIndex))\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39m# Execute the SQL command to create the table\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mbegin() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m      4\u001b[0m     conn\u001b[39m.\u001b[39mexecute(sql2)\n\u001b[0;32m      5\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mC:/Users/Workstation/Documents/Phonepe/data extracted/aggregated_Brands.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sql2 = text('CREATE TABLE agg_userbydevice_table (MyIndex INT NOT NULL AUTO_INCREMENT,State INT,Year INT,Quater INT,Brand VARCHAR(50),Brand_count BIGINT,Brand_percentage BIGINT,PRIMARY KEY (MyIndex))')\n",
    "# Execute the SQL command to create the table\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql2)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/aggregated_Brands.csv')\n",
    "df.to_sql('agg_userbydevice_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14636"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql3 = text('CREATE TABLE district_map_transaction_table (MyIndex INT NOT NULL AUTO_INCREMENT,State INT,Year INT,Quater INT,District VARCHAR(50),Transaction_count BIGINT,Transaction_amount BIGINT,PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql3)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/map_Transaction.csv')\n",
    "df.to_sql('district_map_transaction_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14640"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql4 = text('CREATE TABLE district_map_registering_table (MyIndex INT NOT NULL AUTO_INCREMENT,State INT,Year INT,Quater INT,District VARCHAR(50),Registered_user BIGINT,App_opening BIGINT,PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql4)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/map_users.csv')\n",
    "df.to_sql('district_map_registering_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql5 = text('CREATE TABLE top_transaction_table(MyIndex INT NOT NULL AUTO_INCREMENT,State VARCHAR(50),District VARCHAR(50),Transaction_count BIGINT, Transaction_amount BIGINT,PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql5)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/top_transaction.csv')\n",
    "df.to_sql('top_transaction_table',con=connection, if_exists= \"replace\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7140"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql6 = text('CREATE TABLE top_users_table(MyIndex INT NOT NULL AUTO_INCREMENT,State VARCHAR(50),District_Pincode VARCHAR(50),RegisteredUser BIGINT,PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql6)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/Top_users.csv')\n",
    "df.to_sql('top_users_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geo-visulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql7 = text('CREATE TABLE longitude_latitude_state_table (MyIndex INT NOT NULL AUTO_INCREMENT,Code VARCHAR(50),Latitude BIGINT, Longitude BIGINT, State VARCHAR(50),PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql7)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted/Longitude_Latitude_State_Table.csv')\n",
    "df.to_sql('longitude_latitude_state_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql8 = text('CREATE TABLE districts_longitude_latitude_table(MyIndex INT NOT NULL AUTO_INCREMENT,State VARCHAR(50),District VARCHAR(50),Latitude BIGINT, Longitude BIGINT,PRIMARY KEY (MyIndex))')\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(sql8)\n",
    "df = pd.read_csv('C:/Users/Workstation/Documents/Phonepe/data extracted//Data_Map_Districts_Longitude_Latitude.csv')\n",
    "df.to_sql('districts_longitude_latitude_table',con=connection, if_exists= \"replace\",index=False, chunksize=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Beast_20220927",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e186648c2e2a16010a4bd630ba1621e1bc3b7a133fa5accf977a6190bb3db42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
